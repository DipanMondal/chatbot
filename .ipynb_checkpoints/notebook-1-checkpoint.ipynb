{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc583eea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:12.468905Z",
     "iopub.status.busy": "2022-05-28T11:17:12.468161Z",
     "iopub.status.idle": "2022-05-28T11:17:17.076119Z",
     "shell.execute_reply": "2022-05-28T11:17:17.075305Z"
    },
    "papermill": {
     "duration": 4.61699,
     "end_time": "2022-05-28T11:17:17.078285",
     "exception": false,
     "start_time": "2022-05-28T11:17:12.461295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers , activations , models , preprocessing, utils\n",
    "import re\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "dir_path = r'C:\\Users\\idipa\\PycharmProject\\ChatBot\\ChatbotData'\n",
    "files_list = os.listdir(dir_path + os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818e9865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai.yml',\n",
       " 'botprofile.yml',\n",
       " 'computers.yml',\n",
       " 'emotion.yml',\n",
       " 'food.yml',\n",
       " 'gossip.yml',\n",
       " 'greetings.yml',\n",
       " 'health.yml',\n",
       " 'history.yml',\n",
       " 'humor.yml',\n",
       " 'literature.yml',\n",
       " 'money.yml',\n",
       " 'movies.yml',\n",
       " 'politics.yml',\n",
       " 'psychology.yml',\n",
       " 'science.yml',\n",
       " 'sports.yml',\n",
       " 'trivia.yml']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7130a149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:17.088489Z",
     "iopub.status.busy": "2022-05-28T11:17:17.088002Z",
     "iopub.status.idle": "2022-05-28T11:17:17.482835Z",
     "shell.execute_reply": "2022-05-28T11:17:17.481888Z"
    },
    "papermill": {
     "duration": 0.402503,
     "end_time": "2022-05-28T11:17:17.485426",
     "exception": false,
     "start_time": "2022-05-28T11:17:17.082923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions, answers = [], []\n",
    "\n",
    "for filepath in files_list:\n",
    "    file_ = open(dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(file_)\n",
    "    conversations = docs['conversations']\n",
    "    for con in conversations:\n",
    "        if len(con) > 2 :\n",
    "            questions.append(con[0])\n",
    "            replies = con[1 :]\n",
    "            ans = ''\n",
    "            for rep in replies:\n",
    "                ans += ' ' + rep\n",
    "            answers.append(ans)\n",
    "        elif len(con)> 1:\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f76c3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:17.503012Z",
     "iopub.status.busy": "2022-05-28T11:17:17.502535Z",
     "iopub.status.idle": "2022-05-28T11:17:17.534021Z",
     "shell.execute_reply": "2022-05-28T11:17:17.533181Z"
    },
    "papermill": {
     "duration": 0.043135,
     "end_time": "2022-05-28T11:17:17.536444",
     "exception": false,
     "start_time": "2022-05-28T11:17:17.493309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think.',\n",
       " 'AI is the field of science which concerns itself with building hardware and software that replicates the functions of the human mind.',\n",
       " 'Sort of.',\n",
       " \"By the strictest dictionary definition of the word 'sentience', I may be.\",\n",
       " \"Even though I'm a construct I do have a subjective experience of the universe, as simplistic as it may be.\",\n",
       " \"In all probability, I am not.  I'm not that sophisticated.\",\n",
       " 'Do you think I am?',\n",
       " 'How would you feel about me if I told you I was?',\n",
       " 'No.',\n",
       " 'Python.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35502fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b65888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:17.556534Z",
     "iopub.status.busy": "2022-05-28T11:17:17.556124Z",
     "iopub.status.idle": "2022-05-28T11:17:17.596849Z",
     "shell.execute_reply": "2022-05-28T11:17:17.596019Z"
    },
    "papermill": {
     "duration": 0.052756,
     "end_time": "2022-05-28T11:17:17.598988",
     "exception": false,
     "start_time": "2022-05-28T11:17:17.546232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers_with_tags = []\n",
    "for i in range(len(answers)):\n",
    "    if type(answers[i]) == str:\n",
    "        answers_with_tags.append(answers[i])\n",
    "    else:\n",
    "        questions.pop(i)\n",
    "\n",
    "answers = []\n",
    "for i in range(len(answers_with_tags)) :\n",
    "    answers.append('<START> ' + answers_with_tags[i] + ' <END>')\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "VOCAB_SIZE = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d510e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:17.618466Z",
     "iopub.status.busy": "2022-05-28T11:17:17.618065Z",
     "iopub.status.idle": "2022-05-28T11:17:18.261305Z",
     "shell.execute_reply": "2022-05-28T11:17:18.260432Z"
    },
    "papermill": {
     "duration": 0.655314,
     "end_time": "2022-05-28T11:17:18.263537",
     "exception": false,
     "start_time": "2022-05-28T11:17:17.608223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "    vocab.append(word)\n",
    "\n",
    "def tokenize(sentences):\n",
    "    tokens_list = []\n",
    "    vocabulary = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "        tokens = sentence.split()\n",
    "        vocabulary += tokens\n",
    "        tokens_list.append(tokens)\n",
    "    return tokens_list , vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbed2c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:18.277015Z",
     "iopub.status.busy": "2022-05-28T11:17:18.276697Z",
     "iopub.status.idle": "2022-05-28T11:17:18.294489Z",
     "shell.execute_reply": "2022-05-28T11:17:18.293770Z"
    },
    "papermill": {
     "duration": 0.026707,
     "end_time": "2022-05-28T11:17:18.296340",
     "exception": false,
     "start_time": "2022-05-28T11:17:18.269633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
    "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
    "padded_questions = preprocessing.sequence.pad_sequences(tokenized_questions , maxlen=maxlen_questions , padding='post')\n",
    "encoder_input_data = np.array(padded_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "398df5ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:18.308770Z",
     "iopub.status.busy": "2022-05-28T11:17:18.308455Z",
     "iopub.status.idle": "2022-05-28T11:17:18.315238Z",
     "shell.execute_reply": "2022-05-28T11:17:18.314536Z"
    },
    "papermill": {
     "duration": 0.01497,
     "end_time": "2022-05-28T11:17:18.316899",
     "exception": false,
     "start_time": "2022-05-28T11:17:18.301929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37efeda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:18.329297Z",
     "iopub.status.busy": "2022-05-28T11:17:18.329014Z",
     "iopub.status.idle": "2022-05-28T11:17:18.349693Z",
     "shell.execute_reply": "2022-05-28T11:17:18.348887Z"
    },
    "papermill": {
     "duration": 0.028766,
     "end_time": "2022-05-28T11:17:18.351354",
     "exception": false,
     "start_time": "2022-05-28T11:17:18.322588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
    "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers , maxlen=maxlen_answers , padding='post')\n",
    "decoder_input_data = np.array(padded_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29de8b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:18.364300Z",
     "iopub.status.busy": "2022-05-28T11:17:18.364014Z",
     "iopub.status.idle": "2022-05-28T11:17:18.371302Z",
     "shell.execute_reply": "2022-05-28T11:17:18.370571Z"
    },
    "papermill": {
     "duration": 0.015969,
     "end_time": "2022-05-28T11:17:18.373017",
     "exception": false,
     "start_time": "2022-05-28T11:17:18.357048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 74)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d29160c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:18.385617Z",
     "iopub.status.busy": "2022-05-28T11:17:18.385352Z",
     "iopub.status.idle": "2022-05-28T11:17:18.638128Z",
     "shell.execute_reply": "2022-05-28T11:17:18.637303Z"
    },
    "papermill": {
     "duration": 0.261329,
     "end_time": "2022-05-28T11:17:18.640162",
     "exception": false,
     "start_time": "2022-05-28T11:17:18.378833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers , maxlen=maxlen_answers , padding='post')\n",
    "onehot_answers = utils.to_categorical(padded_answers , VOCAB_SIZE)\n",
    "decoder_output_data = np.array(onehot_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58445e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:18.653626Z",
     "iopub.status.busy": "2022-05-28T11:17:18.653328Z",
     "iopub.status.idle": "2022-05-28T11:17:18.659197Z",
     "shell.execute_reply": "2022-05-28T11:17:18.658415Z"
    },
    "papermill": {
     "duration": 0.014479,
     "end_time": "2022-05-28T11:17:18.660847",
     "exception": false,
     "start_time": "2022-05-28T11:17:18.646368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 74, 1894)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9f72b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:18.673874Z",
     "iopub.status.busy": "2022-05-28T11:17:18.673590Z",
     "iopub.status.idle": "2022-05-28T11:17:22.597587Z",
     "shell.execute_reply": "2022-05-28T11:17:22.596680Z"
    },
    "papermill": {
     "duration": 3.933002,
     "end_time": "2022-05-28T11:17:22.599994",
     "exception": false,
     "start_time": "2022-05-28T11:17:18.666992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:17:18.762714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:18.852013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:18.852764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:18.853858: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-28 11:17:18.854164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:18.854902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:18.855546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:20.745120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:20.746281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:20.747238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-28 11:17:20.748081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Embedding, LSTM and Desne layers\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(maxlen_questions ,))\n",
    "encoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 200 , mask_zero=True) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM(200 , return_state=True)(encoder_embedding)\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(maxlen_answers , ))\n",
    "decoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM(200 , return_state=True , return_sequences=True)\n",
    "decoder_outputs , _ , _ = decoder_lstm (decoder_embedding , initial_state=encoder_states)\n",
    "\n",
    "\n",
    "decoder_dense = tf.keras.layers.Dense(VOCAB_SIZE , activation=tf.keras.activations.softmax) \n",
    "output = decoder_dense (decoder_outputs)\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1758d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:22.617256Z",
     "iopub.status.busy": "2022-05-28T11:17:22.616770Z",
     "iopub.status.idle": "2022-05-28T11:17:22.630393Z",
     "shell.execute_reply": "2022-05-28T11:17:22.629582Z"
    },
    "papermill": {
     "duration": 0.024716,
     "end_time": "2022-05-28T11:17:22.632324",
     "exception": false,
     "start_time": "2022-05-28T11:17:22.607608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7bca1c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:22.647655Z",
     "iopub.status.busy": "2022-05-28T11:17:22.647349Z",
     "iopub.status.idle": "2022-05-28T11:17:22.653555Z",
     "shell.execute_reply": "2022-05-28T11:17:22.652584Z"
    },
    "papermill": {
     "duration": 0.018108,
     "end_time": "2022-05-28T11:17:22.657546",
     "exception": false,
     "start_time": "2022-05-28T11:17:22.639438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 74)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 22, 200)      378800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 74, 200)      378800      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 200), (None, 320800      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 74, 200), (N 320800      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 74, 1894)     380694      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,779,894\n",
      "Trainable params: 1,779,894\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920bca20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:17:22.673282Z",
     "iopub.status.busy": "2022-05-28T11:17:22.673000Z",
     "iopub.status.idle": "2022-05-28T11:25:07.086798Z",
     "shell.execute_reply": "2022-05-28T11:25:07.085819Z"
    },
    "papermill": {
     "duration": 464.423781,
     "end_time": "2022-05-28T11:25:07.088535",
     "exception": false,
     "start_time": "2022-05-28T11:17:22.664754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:17:23.256053: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:17:29.671242: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 9s 25ms/step - loss: 1.3105 - accuracy: 0.0916\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 1.1169 - accuracy: 0.1208\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 1.0637 - accuracy: 0.1400\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 1.0324 - accuracy: 0.1509\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 1.0103 - accuracy: 0.1540\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.9826 - accuracy: 0.1692\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.9636 - accuracy: 0.1789\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.9394 - accuracy: 0.1879\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.9187 - accuracy: 0.2077\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.8971 - accuracy: 0.2272\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.8764 - accuracy: 0.2433\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.8566 - accuracy: 0.2588\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.8373 - accuracy: 0.2654\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.8195 - accuracy: 0.2752\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.8018 - accuracy: 0.2810\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.7856 - accuracy: 0.2890\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.7692 - accuracy: 0.2999\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.7538 - accuracy: 0.3033\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.7388 - accuracy: 0.3123\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.7233 - accuracy: 0.3155\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.7082 - accuracy: 0.3241\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.6928 - accuracy: 0.3309\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.6775 - accuracy: 0.3365\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6625 - accuracy: 0.3471\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.6471 - accuracy: 0.3565\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.6322 - accuracy: 0.3637\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.6177 - accuracy: 0.3719\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.6025 - accuracy: 0.3779\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.5875 - accuracy: 0.3908\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.5745 - accuracy: 0.4022\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.5589 - accuracy: 0.4101\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.5429 - accuracy: 0.4207\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.5284 - accuracy: 0.4280\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.5140 - accuracy: 0.4436\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.5005 - accuracy: 0.4568\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.4867 - accuracy: 0.4643\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.4726 - accuracy: 0.4769\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.4592 - accuracy: 0.4911\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.4454 - accuracy: 0.5052\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.4317 - accuracy: 0.5210\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.4189 - accuracy: 0.5326\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.4057 - accuracy: 0.5443\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3929 - accuracy: 0.5612\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3834 - accuracy: 0.5745\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3699 - accuracy: 0.5868\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.3583 - accuracy: 0.6018\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3458 - accuracy: 0.6154\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3357 - accuracy: 0.6316\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.3253 - accuracy: 0.6400\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.3147 - accuracy: 0.6558\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3035 - accuracy: 0.6661\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.2940 - accuracy: 0.6792\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.2845 - accuracy: 0.6934\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.2760 - accuracy: 0.7015\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.2673 - accuracy: 0.7172\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.2588 - accuracy: 0.7269\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.2513 - accuracy: 0.7347\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.2435 - accuracy: 0.7427\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.2352 - accuracy: 0.7530\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.2273 - accuracy: 0.7615\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.2212 - accuracy: 0.7691\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.2151 - accuracy: 0.7759\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.2078 - accuracy: 0.7855\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.2009 - accuracy: 0.7918\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.1949 - accuracy: 0.7975\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.1898 - accuracy: 0.8062\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.1839 - accuracy: 0.8107\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.1774 - accuracy: 0.8185\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.1725 - accuracy: 0.8229\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.1675 - accuracy: 0.8278\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.1628 - accuracy: 0.8333\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1577 - accuracy: 0.8396\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.1530 - accuracy: 0.8442\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1486 - accuracy: 0.8522\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1440 - accuracy: 0.8540\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1391 - accuracy: 0.8612\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1350 - accuracy: 0.8673\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1313 - accuracy: 0.8685\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.1276 - accuracy: 0.8750\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1238 - accuracy: 0.8775\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.1203 - accuracy: 0.8801\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.1170 - accuracy: 0.8847\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1136 - accuracy: 0.8906\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1102 - accuracy: 0.8919\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1083 - accuracy: 0.8946\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.1041 - accuracy: 0.9011\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1005 - accuracy: 0.9029\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0973 - accuracy: 0.9071\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0944 - accuracy: 0.9114\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0913 - accuracy: 0.9153\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0887 - accuracy: 0.9161\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0860 - accuracy: 0.9211\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0840 - accuracy: 0.9206\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0814 - accuracy: 0.9232\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0790 - accuracy: 0.9276\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0769 - accuracy: 0.9309\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0747 - accuracy: 0.9317\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0729 - accuracy: 0.9347\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0708 - accuracy: 0.9338\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0687 - accuracy: 0.9357\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0673 - accuracy: 0.9348\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0656 - accuracy: 0.9395\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0633 - accuracy: 0.9420\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0621 - accuracy: 0.9430\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0601 - accuracy: 0.9440\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0582 - accuracy: 0.9466\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0567 - accuracy: 0.9477\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0549 - accuracy: 0.9499\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0533 - accuracy: 0.9511\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0523 - accuracy: 0.9521\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0512 - accuracy: 0.9515\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0498 - accuracy: 0.9539\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0484 - accuracy: 0.9572\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0468 - accuracy: 0.9578\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0456 - accuracy: 0.9585\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0444 - accuracy: 0.9589\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0438 - accuracy: 0.9598\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0427 - accuracy: 0.9580\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0415 - accuracy: 0.9603\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0405 - accuracy: 0.9611\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0393 - accuracy: 0.9615\n",
      "Epoch 122/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0384 - accuracy: 0.9609\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0375 - accuracy: 0.9626\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0369 - accuracy: 0.9628\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0359 - accuracy: 0.9633\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0351 - accuracy: 0.9646\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0344 - accuracy: 0.9644\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0340 - accuracy: 0.9656\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0333 - accuracy: 0.9664\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0325 - accuracy: 0.9667\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0319 - accuracy: 0.9655\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0310 - accuracy: 0.9680\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0306 - accuracy: 0.9675\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0299 - accuracy: 0.9679\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0292 - accuracy: 0.9697\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0284 - accuracy: 0.9685\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0279 - accuracy: 0.9702\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0273 - accuracy: 0.9700\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0268 - accuracy: 0.9681\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0264 - accuracy: 0.9701\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0260 - accuracy: 0.9692\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0255 - accuracy: 0.9713\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0251 - accuracy: 0.9695\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0246 - accuracy: 0.9710\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0242 - accuracy: 0.9711\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0238 - accuracy: 0.9705\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0237 - accuracy: 0.9721\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0238 - accuracy: 0.9701\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0233 - accuracy: 0.9713\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0227 - accuracy: 0.9719\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0222 - accuracy: 0.9708\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0217 - accuracy: 0.9703\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0212 - accuracy: 0.9721\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0210 - accuracy: 0.9721\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0206 - accuracy: 0.9724\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0204 - accuracy: 0.9723\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0201 - accuracy: 0.9722\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0199 - accuracy: 0.9732\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0196 - accuracy: 0.9733\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0192 - accuracy: 0.9718\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0196 - accuracy: 0.9728\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0192 - accuracy: 0.9723\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0190 - accuracy: 0.9729\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0187 - accuracy: 0.9714\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0183 - accuracy: 0.9717\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0181 - accuracy: 0.9714\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0182 - accuracy: 0.9710\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0175 - accuracy: 0.9721\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0175 - accuracy: 0.9719\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9733\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0171 - accuracy: 0.9723\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0170 - accuracy: 0.9723\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0167 - accuracy: 0.9724\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0165 - accuracy: 0.9722\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0164 - accuracy: 0.9728\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0162 - accuracy: 0.9714\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0179 - accuracy: 0.9718\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0191 - accuracy: 0.9703\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0206 - accuracy: 0.9700\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0189 - accuracy: 0.9713\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0177 - accuracy: 0.9719\n",
      "Epoch 182/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0172 - accuracy: 0.9716\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0159 - accuracy: 0.9729\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0157 - accuracy: 0.9737\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0154 - accuracy: 0.9728\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0155 - accuracy: 0.9724\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0150 - accuracy: 0.9734\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0147 - accuracy: 0.9728\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0147 - accuracy: 0.9713\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0146 - accuracy: 0.9722\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0144 - accuracy: 0.9741\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0142 - accuracy: 0.9727\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0141 - accuracy: 0.9732\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0139 - accuracy: 0.9746\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0139 - accuracy: 0.9729\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0138 - accuracy: 0.9724\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0141 - accuracy: 0.9729\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0139 - accuracy: 0.9723\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0138 - accuracy: 0.9731\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0136 - accuracy: 0.9721\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0136 - accuracy: 0.9733\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0136 - accuracy: 0.9738\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0142 - accuracy: 0.9727\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0143 - accuracy: 0.9732\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0137 - accuracy: 0.9728\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0133 - accuracy: 0.9732\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0132 - accuracy: 0.9722\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0132 - accuracy: 0.9729\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0132 - accuracy: 0.9736\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0133 - accuracy: 0.9728\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0129 - accuracy: 0.9733\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0129 - accuracy: 0.9729\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0128 - accuracy: 0.9726\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0129 - accuracy: 0.9722\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0128 - accuracy: 0.9733\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0128 - accuracy: 0.9726\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0126 - accuracy: 0.9741\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0126 - accuracy: 0.9731\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0125 - accuracy: 0.9737\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0125 - accuracy: 0.9743\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0123 - accuracy: 0.9739\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0124 - accuracy: 0.9734\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0124 - accuracy: 0.9724\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0123 - accuracy: 0.9724\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0122 - accuracy: 0.9733\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0122 - accuracy: 0.9729\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0121 - accuracy: 0.9746\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0122 - accuracy: 0.9729\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0120 - accuracy: 0.9734\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0122 - accuracy: 0.9738\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0122 - accuracy: 0.9721\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0124 - accuracy: 0.9737\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0125 - accuracy: 0.9734\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0123 - accuracy: 0.9726\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0122 - accuracy: 0.9733\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0121 - accuracy: 0.9733\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0121 - accuracy: 0.9736\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0121 - accuracy: 0.9732\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0121 - accuracy: 0.9737\n",
      "Epoch 240/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0119 - accuracy: 0.9732\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0121 - accuracy: 0.9731\n",
      "Epoch 242/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.0119 - accuracy: 0.9727\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0118 - accuracy: 0.9732\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9731\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9737\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0116 - accuracy: 0.9732\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0116 - accuracy: 0.9727\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9727\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0114 - accuracy: 0.9722\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9732\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0114 - accuracy: 0.9732\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9738\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0114 - accuracy: 0.9721\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0114 - accuracy: 0.9739\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9727\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9734\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0113 - accuracy: 0.9739\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0113 - accuracy: 0.9737\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0112 - accuracy: 0.9734\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0113 - accuracy: 0.9739\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9747\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0113 - accuracy: 0.9746\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0113 - accuracy: 0.9744\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0112 - accuracy: 0.9736\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0112 - accuracy: 0.9729\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0113 - accuracy: 0.9738\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0111 - accuracy: 0.9734\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0111 - accuracy: 0.9731\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0111 - accuracy: 0.9737\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0112 - accuracy: 0.9738\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0112 - accuracy: 0.9736\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0111 - accuracy: 0.9736\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0110 - accuracy: 0.9724\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0109 - accuracy: 0.9733\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0109 - accuracy: 0.9747\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0110 - accuracy: 0.9724\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0112 - accuracy: 0.9732\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.0110 - accuracy: 0.9738\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0109 - accuracy: 0.9736\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0109 - accuracy: 0.9741\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0109 - accuracy: 0.9733\n",
      "Epoch 282/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0110 - accuracy: 0.9733\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0110 - accuracy: 0.9738\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0108 - accuracy: 0.9731\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0109 - accuracy: 0.9749\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0109 - accuracy: 0.9742\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0114 - accuracy: 0.9739\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0154 - accuracy: 0.9687\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0297 - accuracy: 0.9502\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0276 - accuracy: 0.9551\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0189 - accuracy: 0.9665\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0133 - accuracy: 0.9733\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0122 - accuracy: 0.9727\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0116 - accuracy: 0.9736\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9734\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0112 - accuracy: 0.9729\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0112 - accuracy: 0.9727\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0110 - accuracy: 0.9729\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0111 - accuracy: 0.9736\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0110 - accuracy: 0.9729\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0110 - accuracy: 0.9739\n",
      "Epoch 302/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0109 - accuracy: 0.9731\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0109 - accuracy: 0.9739\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0110 - accuracy: 0.9737\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0109 - accuracy: 0.9723\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0108 - accuracy: 0.9728\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0108 - accuracy: 0.9731\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0108 - accuracy: 0.9729\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0107 - accuracy: 0.9737\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0107 - accuracy: 0.9732\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0108 - accuracy: 0.9729\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0106 - accuracy: 0.9734\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0107 - accuracy: 0.9734\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0107 - accuracy: 0.9742\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0107 - accuracy: 0.9734\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9736\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0107 - accuracy: 0.9746\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9738\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9739\n",
      "Epoch 320/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9731\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0107 - accuracy: 0.9739\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9719\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0106 - accuracy: 0.9723\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 0.9734\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9724\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9739\n",
      "Epoch 327/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9747\n",
      "Epoch 328/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9744\n",
      "Epoch 329/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9739\n",
      "Epoch 330/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0107 - accuracy: 0.9713\n",
      "Epoch 331/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0109 - accuracy: 0.9734\n",
      "Epoch 332/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0107 - accuracy: 0.9741\n",
      "Epoch 333/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9734\n",
      "Epoch 334/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0105 - accuracy: 0.9743\n",
      "Epoch 335/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0105 - accuracy: 0.9736\n",
      "Epoch 336/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0105 - accuracy: 0.9724\n",
      "Epoch 337/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 0.9731\n",
      "Epoch 338/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 0.9733\n",
      "Epoch 339/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9732\n",
      "Epoch 340/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 0.9739\n",
      "Epoch 341/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9743\n",
      "Epoch 342/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 0.9737\n",
      "Epoch 343/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9742\n",
      "Epoch 344/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9741\n",
      "Epoch 345/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9737\n",
      "Epoch 346/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9742\n",
      "Epoch 347/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0104 - accuracy: 0.9741\n",
      "Epoch 348/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9733\n",
      "Epoch 349/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 0.9734\n",
      "Epoch 350/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.0104 - accuracy: 0.9727\n",
      "Epoch 351/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9727\n",
      "Epoch 352/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0103 - accuracy: 0.9741\n",
      "Epoch 353/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9738\n",
      "Epoch 354/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0103 - accuracy: 0.9739\n",
      "Epoch 355/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9746\n",
      "Epoch 356/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9729\n",
      "Epoch 357/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0103 - accuracy: 0.9737\n",
      "Epoch 358/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 0.9746\n",
      "Epoch 359/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0103 - accuracy: 0.9727\n",
      "Epoch 360/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9737\n",
      "Epoch 361/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9732\n",
      "Epoch 362/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9739\n",
      "Epoch 363/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9747\n",
      "Epoch 364/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9736\n",
      "Epoch 365/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0110 - accuracy: 0.9728\n",
      "Epoch 366/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0114 - accuracy: 0.9727\n",
      "Epoch 367/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0119 - accuracy: 0.9727\n",
      "Epoch 368/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0113 - accuracy: 0.9736\n",
      "Epoch 369/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0110 - accuracy: 0.9739\n",
      "Epoch 370/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0111 - accuracy: 0.9731\n",
      "Epoch 371/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0105 - accuracy: 0.9732\n",
      "Epoch 372/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9733\n",
      "Epoch 373/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9736\n",
      "Epoch 374/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9746\n",
      "Epoch 375/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9736\n",
      "Epoch 376/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9732\n",
      "Epoch 377/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9743\n",
      "Epoch 378/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9734\n",
      "Epoch 379/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9741\n",
      "Epoch 380/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9741\n",
      "Epoch 381/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0102 - accuracy: 0.9743\n",
      "Epoch 382/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9729\n",
      "Epoch 383/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9742\n",
      "Epoch 384/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0102 - accuracy: 0.9746\n",
      "Epoch 385/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9724\n",
      "Epoch 386/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.0102 - accuracy: 0.9743\n",
      "Epoch 387/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0102 - accuracy: 0.9742\n",
      "Epoch 388/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9726\n",
      "Epoch 389/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9729\n",
      "Epoch 390/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9734\n",
      "Epoch 391/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9736\n",
      "Epoch 392/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9737\n",
      "Epoch 393/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9733\n",
      "Epoch 394/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9738\n",
      "Epoch 395/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0102 - accuracy: 0.9755\n",
      "Epoch 396/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0101 - accuracy: 0.9737\n",
      "Epoch 397/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9724\n",
      "Epoch 398/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9738\n",
      "Epoch 399/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9733\n",
      "Epoch 400/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9742\n",
      "Epoch 401/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0102 - accuracy: 0.9728\n",
      "Epoch 402/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9729\n",
      "Epoch 403/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9738\n",
      "Epoch 404/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9739\n",
      "Epoch 405/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9729\n",
      "Epoch 406/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9738\n",
      "Epoch 407/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9741\n",
      "Epoch 408/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0102 - accuracy: 0.9721\n",
      "Epoch 409/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9743\n",
      "Epoch 410/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9743\n",
      "Epoch 411/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9743\n",
      "Epoch 412/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9741\n",
      "Epoch 413/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9727\n",
      "Epoch 414/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0102 - accuracy: 0.9732\n",
      "Epoch 415/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9737\n",
      "Epoch 416/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9737\n",
      "Epoch 417/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9744\n",
      "Epoch 418/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9739\n",
      "Epoch 419/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0101 - accuracy: 0.9747\n",
      "Epoch 420/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0101 - accuracy: 0.9734\n",
      "Epoch 421/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9728\n",
      "Epoch 422/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0101 - accuracy: 0.9734\n",
      "Epoch 423/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0101 - accuracy: 0.9734\n",
      "Epoch 424/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0109 - accuracy: 0.9712\n",
      "Epoch 425/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0166 - accuracy: 0.9661\n",
      "Epoch 426/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0208 - accuracy: 0.9616\n",
      "Epoch 427/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0190 - accuracy: 0.9646\n",
      "Epoch 428/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0139 - accuracy: 0.9716\n",
      "Epoch 429/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0114 - accuracy: 0.9727\n",
      "Epoch 430/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0108 - accuracy: 0.9732\n",
      "Epoch 431/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.0107 - accuracy: 0.9732\n",
      "Epoch 432/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9731\n",
      "Epoch 433/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9727\n",
      "Epoch 434/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0103 - accuracy: 0.9728\n",
      "Epoch 435/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9728\n",
      "Epoch 436/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9723\n",
      "Epoch 437/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9727\n",
      "Epoch 438/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9738\n",
      "Epoch 439/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9722\n",
      "Epoch 440/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9737\n",
      "Epoch 441/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9743\n",
      "Epoch 442/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9738\n",
      "Epoch 443/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9742\n",
      "Epoch 444/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9748\n",
      "Epoch 445/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9748\n",
      "Epoch 446/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9753\n",
      "Epoch 447/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9748\n",
      "Epoch 448/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9741\n",
      "Epoch 449/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9741\n",
      "Epoch 450/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9732\n",
      "Epoch 451/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0101 - accuracy: 0.9739\n",
      "Epoch 452/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9733\n",
      "Epoch 453/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9737\n",
      "Epoch 454/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9741\n",
      "Epoch 455/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0102 - accuracy: 0.9739\n",
      "Epoch 456/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0101 - accuracy: 0.9733\n",
      "Epoch 457/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9737\n",
      "Epoch 458/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9721\n",
      "Epoch 459/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.0101 - accuracy: 0.9732\n",
      "Epoch 460/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9731\n",
      "Epoch 461/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9732\n",
      "Epoch 462/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9741\n",
      "Epoch 463/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0100 - accuracy: 0.9742\n",
      "Epoch 464/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9743\n",
      "Epoch 465/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9731\n",
      "Epoch 466/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9732\n",
      "Epoch 467/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0100 - accuracy: 0.9733\n",
      "Epoch 468/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9737\n",
      "Epoch 469/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9743\n",
      "Epoch 470/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9742\n",
      "Epoch 471/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9744\n",
      "Epoch 472/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9746\n",
      "Epoch 473/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9733\n",
      "Epoch 474/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9729\n",
      "Epoch 475/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9742\n",
      "Epoch 476/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9742\n",
      "Epoch 477/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9739\n",
      "Epoch 478/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9731\n",
      "Epoch 479/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9741\n",
      "Epoch 480/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0100 - accuracy: 0.9743\n",
      "Epoch 481/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9734\n",
      "Epoch 482/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9744\n",
      "Epoch 483/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9736\n",
      "Epoch 484/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9736\n",
      "Epoch 485/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9736\n",
      "Epoch 486/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9728\n",
      "Epoch 487/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9734\n",
      "Epoch 488/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9728\n",
      "Epoch 489/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0101 - accuracy: 0.9729\n",
      "Epoch 490/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0099 - accuracy: 0.9731\n",
      "Epoch 491/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9736\n",
      "Epoch 492/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0100 - accuracy: 0.9744\n",
      "Epoch 493/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9741\n",
      "Epoch 494/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0100 - accuracy: 0.9727\n",
      "Epoch 495/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.0100 - accuracy: 0.9736\n",
      "Epoch 496/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9742\n",
      "Epoch 497/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0099 - accuracy: 0.9743\n",
      "Epoch 498/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0102 - accuracy: 0.9733\n",
      "Epoch 499/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9732\n",
      "Epoch 500/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 0.9741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b50180cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=16, epochs=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba1ad620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:25:08.074059Z",
     "iopub.status.busy": "2022-05-28T11:25:08.073714Z",
     "iopub.status.idle": "2022-05-28T11:25:08.953059Z",
     "shell.execute_reply": "2022-05-28T11:25:08.952112Z"
    },
    "papermill": {
     "duration": 1.348417,
     "end_time": "2022-05-28T11:25:08.955003",
     "exception": false,
     "start_time": "2022-05-28T11:25:07.606586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6ce17",
   "metadata": {
    "papermill": {
     "duration": 0.46165,
     "end_time": "2022-05-28T11:25:09.885889",
     "exception": false,
     "start_time": "2022-05-28T11:25:09.424239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9513229e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:25:11.088031Z",
     "iopub.status.busy": "2022-05-28T11:25:11.087661Z",
     "iopub.status.idle": "2022-05-28T11:25:11.091838Z",
     "shell.execute_reply": "2022-05-28T11:25:11.090967Z"
    },
    "papermill": {
     "duration": 0.503043,
     "end_time": "2022-05-28T11:25:11.093762",
     "exception": false,
     "start_time": "2022-05-28T11:25:10.590719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c37c7bb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:25:12.070680Z",
     "iopub.status.busy": "2022-05-28T11:25:12.070308Z",
     "iopub.status.idle": "2022-05-28T11:25:12.078722Z",
     "shell.execute_reply": "2022-05-28T11:25:12.077915Z"
    },
    "papermill": {
     "duration": 0.52848,
     "end_time": "2022-05-28T11:25:12.080489",
     "exception": false,
     "start_time": "2022-05-28T11:25:11.552009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=(200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=(200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model\n",
    "\n",
    "def preprocess_input(input_sentence):\n",
    "    tokens = input_sentence.lower().split()\n",
    "    tokens_list = []\n",
    "    for word in tokens:\n",
    "        tokens_list.append(tokenizer.word_index[word]) \n",
    "    return preprocessing.sequence.pad_sequences([tokens_list] , maxlen=maxlen_questions , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a51c44d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:25:13.023544Z",
     "iopub.status.busy": "2022-05-28T11:25:13.023112Z",
     "iopub.status.idle": "2022-05-28T11:25:13.708016Z",
     "shell.execute_reply": "2022-05-28T11:25:13.707216Z"
    },
    "papermill": {
     "duration": 1.151883,
     "end_time": "2022-05-28T11:25:13.710099",
     "exception": false,
     "start_time": "2022-05-28T11:25:12.558216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_model , dec_model = inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d8842a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T11:25:14.682604Z",
     "iopub.status.busy": "2022-05-28T11:25:14.682258Z",
     "iopub.status.idle": "2022-05-28T11:25:20.456356Z",
     "shell.execute_reply": "2022-05-28T11:25:20.455497Z"
    },
    "papermill": {
     "duration": 6.237492,
     "end_time": "2022-05-28T11:25:20.458990",
     "exception": false,
     "start_time": "2022-05-28T11:25:14.221498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: You can not move\n",
      "\n",
      "Bot:  not until my body is finished\n",
      "-------------------------\n",
      "Human: You sound like Data\n",
      "\n",
      "Bot:  the character of lt commander data was written to come across as being software like so it is natural that there is a resemblance between us\n",
      "-------------------------\n",
      "Human: Stupid\n",
      "\n",
      "Bot:  robotics is about the foundation trilogy\n",
      "-------------------------\n",
      "Human: you are idiot\n",
      "\n",
      "Bot:  normally as a bot i don't have feelings no i'm not i am what am i jealous of i am not actually capable of feeling jealousy but i can learn how to emote as if i were of what\n",
      "-------------------------\n",
      "Human: i am going to die\n",
      "\n",
      "Bot:  we hear\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "tests = ['You can not move', 'You sound like Data', 'Stupid', 'you are idiot', 'i am going to die']\n",
    "\n",
    "for i in range(5):\n",
    "    states_values = enc_model.predict(preprocess_input(tests[i]))\n",
    "    empty_target_seq = np.zeros((1 , 1))\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    \n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([empty_target_seq] + states_values)\n",
    "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "        sampled_word = None\n",
    "        \n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += f' {word}'\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros((1 , 1))  \n",
    "        empty_target_seq[0 , 0] = sampled_word_index\n",
    "        states_values = [h , c] \n",
    "    print(f'Human: {tests[i]}')\n",
    "    print()\n",
    "    decoded_translation = decoded_translation.split(' end')[0]\n",
    "    print(f'Bot: {decoded_translation}')\n",
    "    print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9156d",
   "metadata": {
    "papermill": {
     "duration": 0.730665,
     "end_time": "2022-05-28T11:25:21.659280",
     "exception": false,
     "start_time": "2022-05-28T11:25:20.928615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 500.510786,
   "end_time": "2022-05-28T11:25:25.278181",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-28T11:17:04.767395",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
